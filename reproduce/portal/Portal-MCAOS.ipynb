{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanxh/anaconda3/envs/torch112/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanpy==1.9.1 anndata==0.8.0 umap==0.5.3 numpy==1.23.3 scipy==1.9.3 pandas==1.5.1 scikit-learn==1.1.2 statsmodels==0.13.2 python-igraph==0.10.2 louvain==0.8.0 pynndescent==0.5.7\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import csv\n",
    "import gzip\n",
    "import scipy.io\n",
    "\n",
    "import scipy.sparse as sps\n",
    "\n",
    "from os.path import join\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "sc.settings.verbosity = 3\n",
    "sc.logging.print_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/yanxh/data/MCA/scjoint/data_atlas'\n",
    "\n",
    "adata_atac = sc.read_h5ad(join(data_root, 'adata_atac_cache.h5ad'))\n",
    "adata_rna_facs = sc.read_h5ad('./cache/adata_rna_facs.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_rna = adata_rna_facs.obs\n",
    "meta_atac = adata_atac.obs\n",
    "\n",
    "meta = pd.concat([meta_rna, meta_atac], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration using Portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import portal\n",
    "\n",
    "# Specify the GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Create a folder for saving results\n",
    "result_path = \"./result\"\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding highly variable genes...\n",
      "If you pass `n_top_genes`, all cutoffs are ignored.\n",
      "extracting highly variable genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanxh/anaconda3/envs/torch112/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:62: UserWarning: `flavor='seurat_v3'` expects raw count data, but non-integers were found.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> added\n",
      "    'highly_variable', boolean vector (adata.var)\n",
      "    'highly_variable_rank', float vector (adata.var)\n",
      "    'means', float vector (adata.var)\n",
      "    'variances', float vector (adata.var)\n",
      "    'variances_norm', float vector (adata.var)\n",
      "If you pass `n_top_genes`, all cutoffs are ignored.\n",
      "extracting highly variable genes\n",
      "--> added\n",
      "    'highly_variable', boolean vector (adata.var)\n",
      "    'highly_variable_rank', float vector (adata.var)\n",
      "    'means', float vector (adata.var)\n",
      "    'variances', float vector (adata.var)\n",
      "    'variances_norm', float vector (adata.var)\n",
      "Normalizing and scaling...\n",
      "normalizing counts per cell\n",
      "    finished (0:00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanxh/gitrepo/Portal-main/portal/model.py:66: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  hvg_total = hvg_A & hvg_B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... as `zero_center=True`, sparse input is densified and may lead to large memory consumption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanxh/anaconda3/envs/torch112/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing counts per cell\n",
      "    finished (0:00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanxh/anaconda3/envs/torch112/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... as `zero_center=True`, sparse input is densified and may lead to large memory consumption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanxh/anaconda3/envs/torch112/lib/python3.8/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality reduction via PCA...\n",
      "Begining time:  Tue Mar  7 11:56:40 2023\n",
      "step 0, loss_D=9.284319, loss_GAN=2.951206, loss_AE=222.320526, loss_cos=19.603338, loss_LA=163.271332\n",
      "step 200, loss_D=1.674860, loss_GAN=5.944926, loss_AE=9.162988, loss_cos=6.147538, loss_LA=2.821856\n",
      "step 400, loss_D=1.793508, loss_GAN=4.827241, loss_AE=5.746913, loss_cos=5.099998, loss_LA=1.568431\n",
      "step 600, loss_D=1.981043, loss_GAN=4.464570, loss_AE=4.823460, loss_cos=4.676253, loss_LA=1.075558\n",
      "step 800, loss_D=1.645749, loss_GAN=4.494967, loss_AE=4.126327, loss_cos=4.827905, loss_LA=0.883243\n",
      "step 1000, loss_D=1.589784, loss_GAN=4.762619, loss_AE=4.002243, loss_cos=4.158810, loss_LA=0.765795\n",
      "step 1200, loss_D=1.626206, loss_GAN=4.761108, loss_AE=3.588576, loss_cos=4.731690, loss_LA=0.701957\n",
      "step 1400, loss_D=1.439348, loss_GAN=4.873697, loss_AE=3.418447, loss_cos=4.043716, loss_LA=0.526594\n",
      "step 1600, loss_D=1.439572, loss_GAN=4.758642, loss_AE=3.113201, loss_cos=4.384361, loss_LA=0.480056\n",
      "step 1800, loss_D=1.607013, loss_GAN=4.957835, loss_AE=3.355348, loss_cos=4.054558, loss_LA=0.543375\n",
      "step 2000, loss_D=1.582922, loss_GAN=4.936716, loss_AE=3.479546, loss_cos=4.931429, loss_LA=0.624202\n",
      "step 2200, loss_D=1.486968, loss_GAN=4.980014, loss_AE=3.281744, loss_cos=4.078796, loss_LA=0.420392\n",
      "step 2400, loss_D=1.546027, loss_GAN=4.897698, loss_AE=3.013669, loss_cos=4.133742, loss_LA=0.414249\n",
      "step 2600, loss_D=1.374563, loss_GAN=5.063810, loss_AE=2.927198, loss_cos=4.160294, loss_LA=0.390225\n",
      "step 2800, loss_D=1.440980, loss_GAN=4.883975, loss_AE=3.012310, loss_cos=4.074424, loss_LA=0.330437\n",
      "Ending time:  Tue Mar  7 11:57:32 2023\n",
      "Training takes 51.32 seconds\n",
      "Begining time:  Tue Mar  7 11:57:32 2023\n",
      "Ending time:  Tue Mar  7 11:57:32 2023\n",
      "Evaluating takes 0.02 seconds\n"
     ]
    }
   ],
   "source": [
    "## standard portal pipeline\n",
    "\n",
    "model = portal.model.Model(training_steps=3000, \n",
    "                           lambdacos=10., lambdaAE=10., lambdaLA=10., lambdaGAN=1.0)\n",
    "model.preprocess(adata_rna_facs, adata_atac, hvg_num=4000, norm_pca=False) # perform preprocess and PCA\n",
    "model.train() # train the model\n",
    "model.eval() # get integrated latent representation of cells\n",
    "\n",
    "# portal.utils.plot_UMAP(model.latent, meta, colors=[\"domain\", \"cell_type\"], save=False, result_path=result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7581779962823342"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from portal.knn_classifier import knn_classifier_top_k, faiss_knn, knn_classifier_prob_concerto\n",
    "rna_lab = np.array(adata_rna_facs.obs.cell_type.values)\n",
    "atac_lab = np.array(adata_atac.obs.cell_type.values)\n",
    "\n",
    "feat_A, feat_B = model.latent[:len(rna_lab)], model.latent[len(rna_lab):]\n",
    "# feat_A, feat_B = normalize(feat_A, axis=1), normalize(feat_B, axis=1)\n",
    "\n",
    "# knn_classifier\n",
    "atac_pred, atac_prob = knn_classifier_prob_concerto(feat_A, feat_B, rna_lab, n_sample=None, knn=30, num_chunks=100)\n",
    "\n",
    "shr_mask = np.in1d(atac_lab, np.unique(rna_lab))\n",
    "(np.ravel(atac_pred)[shr_mask] == atac_lab[shr_mask]).mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "close_acc= 0.7533\n",
      "AUROC= 0.7785\n",
      "AUPR= 0.5925\n",
      "OSCR= 0.6267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7533137605753696, 0.7785080899484507, 0.5925281976095327, 0.626651700613932)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from portal.metrics import osr_evaluator\n",
    "\n",
    "open_score = 1 - atac_prob\n",
    "\n",
    "kn_data_pr = atac_pred[shr_mask]\n",
    "kn_data_gt = atac_lab[shr_mask]\n",
    "kn_data_open_score = open_score[shr_mask]\n",
    "\n",
    "unk_data_open_score = open_score[np.logical_not(shr_mask)]\n",
    "\n",
    "closed_acc, os_auroc, os_aupr, oscr = osr_evaluator(kn_data_pr, kn_data_gt, kn_data_open_score, unk_data_open_score)\n",
    "closed_acc, os_auroc, os_aupr, oscr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch171",
   "language": "python",
   "name": "torch171"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

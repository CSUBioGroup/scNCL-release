{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "sys.path.append(\"../\")\n",
    "from concerto_function5_3 import *\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sps\n",
    "import matplotlib.pyplot as plt\n",
    "from metrics import osr_evaluator\n",
    "\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select an available GPU to run on a multi-GPU computer or you can run it directly on the CPU without executing this cell\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1' \n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = 'HumanFetal_100k'\n",
    "\n",
    "adata_rna  = sc.read_h5ad('/home/yanxh/data/HumanFetal_100k/RNA/adata_rna_sampled.h5ad')\n",
    "adata_atac = sc.read_h5ad('/home/yanxh/data/HumanFetal_100k/ATAC/adata_atac.h5ad')\n",
    "\n",
    "adata_rna.obs['domain'] = 'RNA'\n",
    "adata_atac.obs['domain']= 'ATAC'\n",
    "\n",
    "adata_rna.obs['cell_type'] = adata_rna.obs['Main_cluster_name'].values\n",
    "\n",
    "batch_key = 'domain'\n",
    "type_key = 'cell_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_all = sc.concat([adata_rna, adata_atac])\n",
    "adata_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter cells, normalize_total, hvg(if), no scale\n",
    "adata = preprocessing_rna(adata_all, \n",
    "                          min_features=0, \n",
    "                          n_top_features=None, \n",
    "                          is_hvg=False, \n",
    "                          batch_key=batch_key)\n",
    "\n",
    "adata_ref = adata[adata.obs[batch_key] == 'RNA']\n",
    "adata_query = adata[adata.obs[batch_key] == 'ATAC']\n",
    "\n",
    "shr_mask = np.in1d(adata_query.obs[type_key], adata_ref.obs[type_key].unique())\n",
    "atac_lab = np.array(adata_query.obs[type_key].values)\n",
    "\n",
    "save_path = './'\n",
    "# if not os.path.exists(save_path):\n",
    "#     os.makedirs(save_path)\n",
    "# adata_ref.write_h5ad(save_path + 'adata_ref.h5ad')\n",
    "# adata_query.write_h5ad(save_path + 'adata_query.h5ad')  # .tech=='indrop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_time = datetime.datetime.now()\n",
    "\n",
    "pp_cost = (ed_time-st_time).total_seconds()\n",
    "print('pp cost ', pp_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ref_tf_path = concerto_make_tfrecord_supervised(adata_ref, tf_path = save_path + f'tfrecord/{exp_id}/ref_tf/',\n",
    "                                     batch_col_name = batch_key, label_col_name=type_key)\n",
    "query_tf_path = concerto_make_tfrecord_supervised(adata_query, tf_path = save_path + f'tfrecord/{exp_id}/query_tf/',\n",
    "                                     batch_col_name = batch_key, label_col_name=type_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_time = datetime.datetime.now()\n",
    "\n",
    "rec_cost = (ed_time-st_time).total_seconds()\n",
    "print('rec cost ', rec_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train (leave spleen out). If you don't want to train the model, you can just load our trained classifier's weight and test it directly.\n",
    "weight_path = save_path + f'weight/{exp_id}/'\n",
    "ref_tf_path = save_path + f'tfrecord/{exp_id}/ref_tf/'\n",
    "query_tf_path = save_path + f'tfrecord/{exp_id}/query_tf/'\n",
    "\n",
    "concerto_train_inter_supervised_uda2(ref_tf_path, query_tf_path, weight_path,\n",
    "                                     super_parameters={'batch_size': 128, 'epoch_pretrain': 1,'epoch_classifier': 10, 'lr': 1e-4,'drop_rate': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_time = datetime.datetime.now()\n",
    "\n",
    "train_cost = (ed_time-st_time).total_seconds()\n",
    "print('train cost ', train_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test (only spleen)\n",
    "weight_path = save_path + f'weight/{exp_id}/'\n",
    "ref_tf_path = save_path + f'tfrecord/{exp_id}/ref_tf/'\n",
    "query_tf_path = save_path + f'tfrecord/{exp_id}/query_tf/'\n",
    "\n",
    "for epoch in [4]:\n",
    "    st_time = datetime.datetime.now()\n",
    "    results = concerto_test_inter_supervised2(weight_path, ref_tf_path, query_tf_path,\n",
    "                                         super_parameters = {'batch_size': 64, 'epoch': epoch, 'lr': 1e-5,'drop_rate': 0.1})\n",
    "    ed_time = datetime.datetime.now()\n",
    "\n",
    "    test_cost = (ed_time-st_time).total_seconds()\n",
    "    print('test cost ', test_cost)\n",
    "    \n",
    "    # NN classifier\n",
    "    query_neighbor, query_prob = knn_classifier(results['source_feature'],\n",
    "                                           results['target_feature'],\n",
    "                                           adata_ref,\n",
    "                                           adata_ref.obs_names,\n",
    "                                           column_name=type_key,\n",
    "                                           k=30)\n",
    "    open_score = 1 - query_prob\n",
    "\n",
    "    kn_data_pr = query_neighbor[shr_mask]\n",
    "    kn_data_gt = atac_lab[shr_mask]\n",
    "    kn_data_open_score = open_score[shr_mask]\n",
    "\n",
    "    unk_data_open_score = open_score[np.logical_not(shr_mask)]\n",
    "\n",
    "    closed_acc, os_auroc, os_aupr, oscr = osr_evaluator(kn_data_pr, kn_data_gt, kn_data_open_score, unk_data_open_score)\n",
    "    print(closed_acc, os_auroc, os_aupr, oscr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompressSSC",
   "language": "python",
   "name": "compressssc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
